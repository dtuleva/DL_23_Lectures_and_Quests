{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmSN+/FGk42IdK983THadx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtuleva/DL_23_Lectures_and_Quests/blob/main/bonus_lecture_PyTorch_and__JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "VpYZQy2b_qQB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn # beware of namespace; there is nn in tensorflow and jax too\n",
        "import torch.nn.functional  as F\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms as T\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch and JAX\n",
        "### bonus lecture"
      ],
      "metadata": {
        "id": "9LTS9fkI_uf2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2jOZHrzyAEE7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch"
      ],
      "metadata": {
        "id": "ttfiZHUHzm8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7lQlbLF_63l",
        "outputId": "e1e64af9-2522-49bd-d604-53d1f301bfc1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor(2, 5) # 2, 5 is shape; makes a tensor that is not initialised; values are whatever happens to be in memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGGZaLCCBqNx",
        "outputId": "9b549636-02db-413b-826a-0c8b42d03bf0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6530e+04, -1.4582e-29, -1.0683e-30,  4.4556e-41,  1.4634e+27],\n",
              "        [ 3.3328e-41,  2.7016e-01, -2.4773e+27, -1.0684e-30,  4.4556e-41]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros(2, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEvbxMOvCsyC",
        "outputId": "6a565888-0dca-4209-f20f-64c97a496f49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(2, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T5qqs6LDI5D",
        "outputId": "e25ff20a-a851-4387-b788-832d734b8af2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand((2000, 6)) # torch.random for other distributions\n",
        "b = torch.rand((2000, 6))\n",
        "w = torch.rand((6, 1)) # broadcasting - rank 1 tensor does not transpose properly (same as numpy)"
      ],
      "metadata": {
        "id": "dfCqOrW0DLmB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a == b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Djp4_YaDnPh",
        "outputId": "8d15bd04-507b-496b-a319-5d24aa6dbb9a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False],\n",
              "        ...,\n",
              "        [False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.all(a == b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLpLJR5BDo1C",
        "outputId": "745cd132-d5bb-4205-e1b6-efc0e49f30c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.all((a + b) == torch.add(a, b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taYV5PdoDxDi",
        "outputId": "a893f1cd-03cb-4751-918d-eb2202326f57"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a @ b.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyMjtRDoEWXj",
        "outputId": "7adc0a49-a296-4b87-c86e-2a77fcc40aa9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.9679, 1.3703, 0.5412,  ..., 1.8931, 2.0269, 1.0519],\n",
              "        [2.5619, 2.4325, 1.0554,  ..., 2.3591, 2.4811, 1.9754],\n",
              "        [1.7998, 1.7647, 0.5770,  ..., 1.9659, 1.8367, 1.2914],\n",
              "        ...,\n",
              "        [2.5941, 2.5057, 0.8755,  ..., 2.5807, 2.3239, 2.1538],\n",
              "        [2.1918, 2.0499, 0.7826,  ..., 2.1228, 2.1131, 1.5947],\n",
              "        [1.4191, 1.6143, 0.5335,  ..., 1.6043, 1.3390, 1.4092]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(b, a.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnICXakaEYkC",
        "outputId": "02a5e042-3d34-4772-8cea-486596ce52b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.9679, 2.5619, 1.7998,  ..., 2.5941, 2.1918, 1.4191],\n",
              "        [1.3703, 2.4325, 1.7647,  ..., 2.5057, 2.0499, 1.6143],\n",
              "        [0.5412, 1.0554, 0.5770,  ..., 0.8755, 0.7826, 0.5335],\n",
              "        ...,\n",
              "        [1.8931, 2.3591, 1.9659,  ..., 2.5807, 2.1228, 1.6043],\n",
              "        [2.0269, 2.4811, 1.8367,  ..., 2.3239, 2.1131, 1.3390],\n",
              "        [1.0519, 1.9754, 1.2914,  ..., 2.1538, 1.5947, 1.4092]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(a @ w).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjTDAOnqEapy",
        "outputId": "5a1ea878-b9bc-4682-e08c-91b9ce672238"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = a @ w + b"
      ],
      "metadata": {
        "id": "rtP2xDjwFQX6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTKuMojiJ7vr",
        "outputId": "1467a292-485d-46e4-88db-d6230f50a0da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2484)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.relu(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gE59il-FU_p",
        "outputId": "d28de5dd-0c93-4592-bc2e-e52167e9d6ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.9890, 1.9788, 2.1750, 1.6651, 2.1923, 2.1987],\n",
              "        [2.7619, 2.7259, 2.3750, 2.5936, 2.6207, 2.1985],\n",
              "        [1.4131, 1.6463, 1.3190, 1.2277, 1.2731, 1.3429],\n",
              "        ...,\n",
              "        [2.3195, 2.5820, 2.5913, 2.4421, 2.8830, 2.5196],\n",
              "        [2.0280, 2.3811, 2.0429, 1.6231, 2.4666, 2.4353],\n",
              "        [0.9770, 1.6427, 1.7317, 1.6054, 1.0499, 1.0413]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2NKGbWiFWI5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_np = np.linspace(-5, 5, 5000)\n",
        "y_np = np.sin(x_np)"
      ],
      "metadata": {
        "id": "Eg9yP6H7Kiff"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_torch = torch.tensor(x_np)\n",
        "type(x_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Wys8BZKt7T",
        "outputId": "4796e12a-69c1-4b85-f482-4d4753661f54"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.sin(x_np) # cannot feed np array directly to torch function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "vr6kRHOLK7sj",
        "outputId": "e1962b1d-c442-46c9-d033-1d9be3662862"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9c6d77a877b1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_np\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cannot feed np array directly to torch function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: sin(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_torch = torch.sin(x_torch)\n",
        "# or\n",
        "x_torch.sin()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2dPZUcWLZXL",
        "outputId": "cd563558-2f92-49c2-cc00-91987904b3f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.9589,  0.9595,  0.9601,  ..., -0.9601, -0.9595, -0.9589],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can be chained for unary operations\n",
        "torch.all(x_torch.sin().cos()) == torch.all(torch.cos(torch.sin(x_torch)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9n8RcMdLreT",
        "outputId": "fd5ba9eb-fdf5-49ab-9e41-d26afec001e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_torch[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70YYN99pMc6D",
        "outputId": "c2263cd8-450d-4da7-a5a2-196ea461df90"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-5.0000, -4.9980, -4.9960, -4.9940], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LmXeL-SUM8Cf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMhvF5iiNbl2",
        "outputId": "3021f497-313e-4971-f1ca-e37e0bbde368"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0384, 0.2375, 0.5277, 0.0180, 0.9075, 0.8341],\n",
              "        [0.7880, 0.8561, 0.7752, 0.3091, 0.3838, 0.7539],\n",
              "        [0.1276, 0.3420, 0.0805, 0.7693, 0.8514, 0.7210],\n",
              "        ...,\n",
              "        [0.5821, 0.4344, 0.9042, 0.8116, 0.6900, 0.6551],\n",
              "        [0.5093, 0.4564, 0.4329, 0.6109, 0.5183, 0.8863],\n",
              "        [0.1575, 0.4227, 0.2419, 0.8466, 0.4823, 0.3494]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYJLMD9jNcQk",
        "outputId": "5d599fd1-af8c-4bf3-ea1a-ea92936af15f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2375, 0.8561, 0.3420,  ..., 0.4344, 0.4564, 0.4227])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7mLZ8z9Ndsb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradients"
      ],
      "metadata": {
        "id": "ISFAsTH2N7J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4I8wBL8N6AS",
        "outputId": "4da6f6af-f838-46f3-db86-c31d5ab1d0f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.9589,  0.9595,  0.9601,  ..., -0.9601, -0.9595, -0.9589],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_torch.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaApPnbDN9xb",
        "outputId": "f5be6b32-b4e2-4615-c9d0-842c026c8a05"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(y_torch.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLh1gZfxOAY7",
        "outputId": "0a5f1b2f-bbc2-48a3-c15b-7de4408e312e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_torch = torch.tensor(x_np, requires_grad = True) # state that gradients are needed by initialisation / reinitialisation of variable\n",
        "# x_torch = torch.tensor(x_torch, requires_grad = True)\n"
      ],
      "metadata": {
        "id": "k3R_J5jdOo2h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_torch = torch.sin(x_torch)"
      ],
      "metadata": {
        "id": "zTNDO-FWOF8E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_torch.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "a4q54urYOazL",
        "outputId": "62fd1a9e-dd41-4243-9edc-e47483766a02"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-0fdf549e85fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_torch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    118\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_torch.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usKS16s1PrUU",
        "outputId": "c728cfe4-849a-43c6-9739-c5ce86e6ee06"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-8de13210a3da>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  y_torch.grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_torch.grad"
      ],
      "metadata": {
        "id": "eZ6HGhwtP1X7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2oUwONpQD2r"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2, 3, 5], dtype = float, requires_grad = True)\n",
        "b = torch.tensor([8.0, 15, -2])\n"
      ],
      "metadata": {
        "id": "ZdnQ2WGbQfDJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = (2 * a ** 2 + 3 * b)** 3"
      ],
      "metadata": {
        "id": "IAEX3MY7QzYM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward(torch.tensor([1, 1, 1]))"
      ],
      "metadata": {
        "id": "u7CAVpnERuID"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "id": "olRrd7ZTRvm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de656dd0-a146-4aaa-c4e6-eca6df635926"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 24576., 142884., 116160.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad is None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtFA0ImUMU21",
        "outputId": "5b60b7e8-7a76-4869-ad83-8e15a8043b89"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRuPVmq-Mnyd",
        "outputId": "fa5d769b-276f-4393-bea3-cacabc190c5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-10b3a7061f6d>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  y.grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This way grad is directly calculated from scratch each time, not optimal for NN; even the same operation on same inputs is calculated again - slow and computationally expensive. What we need is compiling, which in pytorch is not defined very well (unlike tensorflow and jax)"
      ],
      "metadata": {
        "id": "4BO_aXwiOAeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data = torch.rand((20, 2)) # need float tensors everywhere"
      ],
      "metadata": {
        "id": "IdO3ZQXVRVEc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fully_connected_layer = torch.nn.Linear(2, 3) # no input layer syntax sugar, need to explicitly state the in and output shapes, no inpit dynamic"
      ],
      "metadata": {
        "id": "5GosRvbiM0Rl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = fully_connected_layer(mock_data)\n",
        "\n",
        "# equiv to tf.keras.layers.Dense(30)(mock_data)"
      ],
      "metadata": {
        "id": "x9pAuJFAQyre"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMtyx9MtTWH9",
        "outputId": "1890fc62-7040-4f96-e845-edd56dd2a6ac"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3399, grad_fn=<MinBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activation = torch.nn.functional.relu(z)"
      ],
      "metadata": {
        "id": "jTlBqmAGRE4u"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyyE8IFYStG2",
        "outputId": "e6578902-b98d-473d-8956-95d63c918576"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0., grad_fn=<MinBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.MSELoss(activation, y_expected).backward()"
      ],
      "metadata": {
        "id": "-LRzkO81Tbw3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YuOAAg7uZFlt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data = torch.rand((1, 28, 28))  # in pytorch images are (channels, height, width)\n",
        "mock_labels = torch.rand(20, 10)"
      ],
      "metadata": {
        "id": "n4NugKduUzD1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self): # only architecture, no functions (relu, ...) here\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 3, padding = \"same\") # or kernel (3, 3)\n",
        "    self.pool = nn.MaxPool2d(kernel_size = 2) # needs initialisation, but can be used multiple times after different layers (unlike tf)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size = 3)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dense1 = nn.Linear(in_features = 6 * 6, out_features = 25) # need to calc in dimentions\n",
        "    self.dense2 = nn.Linear(25, 10) # 10 as num classes\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.flatten(x)\n",
        "    x = F.relu(self.dense1(x))\n",
        "    x = self.dense2(x) # don't need activation, here crossenthropy works properly with direct input\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "D4Eb7Qx5Uy1M"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0x4cVfBVNB3",
        "outputId": "c00f9920-2c8f-4681-9c2c-abc0d39c044b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (dense1): Linear(in_features=36, out_features=25, bias=True)\n",
              "  (dense2): Linear(in_features=25, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward(mock_data).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5hd0pd-YLhY",
        "outputId": "06b37880-a6dd-46d0-e49e-db4bbf3f9048"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.forward(mock_data).view(-1, 1) # = reshape(whatever rows, 1 column)"
      ],
      "metadata": {
        "id": "Psz-h-gDY_OR"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [param for param in model.parameters()] # trainable params"
      ],
      "metadata": {
        "id": "-zvzvcgPeLVx"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM5HKXlgg3Xj",
        "outputId": "0604aab0-edb2-476c-92f0-d6750cff55f9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (dense1): Linear(in_features=36, out_features=25, bias=True)\n",
              "  (dense2): Linear(in_features=25, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if we have fancy or scary forward functions we can writhe the backwards method too, if not autograde will take care of it. __Very important__ to remember to call ```zero_grad``` for every train step, so that same calculations are not done again"
      ],
      "metadata": {
        "id": "xxN4HrpchJ3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# __ train step start\n",
        "model.zero_grad()"
      ],
      "metadata": {
        "id": "LYKTiIRFg8ka"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.forward(mock_data)"
      ],
      "metadata": {
        "id": "nb3ilN4Zh0MY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.backward(mock_labels) # 20 examples 10 classes\n",
        "# train step end__"
      ],
      "metadata": {
        "id": "fK1U0VuShnLj"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.conv1.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LMtYBiUjLPp",
        "outputId": "3eb0cbd4-571d-4c38-82dd-ddd02cdf1f0c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.1431,  0.1552, -0.2384,  0.0525, -0.0268,  0.2372,  0.1629,  0.0825,\n",
              "         0.1362, -0.0466], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.conv1.bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIU5HAo2h-Hb",
        "outputId": "af0833de-ed15-4a01-de17-23f333656651"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.9818,  0.0703,  0.0103, -0.3183, -0.0763, -0.9724, -0.0775, -0.4901,\n",
              "        -0.0131, -0.7877])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the gradiens, now we need loss and optimizer.\n",
        "\n",
        "No compiling, here it is done directly:"
      ],
      "metadata": {
        "id": "izMSxOiWjfW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "b3YnPbSkjOFU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss(result, mock_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrajYVrbi7SU",
        "outputId": "aa08ac5e-fb65-469b-fadb-45f3b1798c79"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12.1875, grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.optim.Adam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd6z50tclj7U",
        "outputId": "1fe8ccd2-ba04-448a-e663-b142097aca0e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.optim.adam.Adam"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No ```.fit```; need to apply adam on forward + backward; then skip backward for inference"
      ],
      "metadata": {
        "id": "l2J4KjINsHiT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrWTYVnesHHG"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ready datasets:\n",
        "\n",
        "unlike tf, torch makes difference between dataset and way to work with said dataset"
      ],
      "metadata": {
        "id": "V4EPL3ostEK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CIFAR10(root = \".\", download = True, transform = T.ToTensor()) # transform = [] preprocess and augmentation here; can add custom functions to the list\n",
        "                                                                            # if we list function composition, dataset element cannot be called directly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wibKdx1mBqM",
        "outputId": "9b26e150-a6e5-4b5a-d74f-91493aac2097"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 78062842.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = torch.utils.data.DataLoader(train_data, batch_size = 4, num_workers = 2) # num_workers = how may batches to get at once"
      ],
      "metadata": {
        "id": "wf8cr5K_tOJ5"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haTfcr48uNn3",
        "outputId": "1d356b0b-dc65-4641-a9e1-da9958d3507a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
              "          [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
              "          [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
              "          ...,\n",
              "          [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
              "          [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
              "          [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
              " \n",
              "         [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
              "          [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
              "          [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
              "          ...,\n",
              "          [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
              "          [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
              "          [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
              " \n",
              "         [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
              "          [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
              "          [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
              "          ...,\n",
              "          [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
              "          [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
              "          [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]]),\n",
              " 6)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T.ToTensor # reordes to (channels, height, width) from (w, h, ch) and rescales to (0, 1) from (0, 255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmrE9JqKupiX",
        "outputId": "a85031d5-b39f-4f38-97e4-857232da83be"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.transforms.transforms.ToTensor"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader.generator # no pre-fetch function :("
      ],
      "metadata": {
        "id": "z7hxLDAyvElP"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pytorch lightning for training steps"
      ],
      "metadata": {
        "id": "6fF-LhOPgRlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best reason to engage with pytorch as of now:\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "id": "YeGxloEwjCEx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-73jIt4kzK_I"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyH3zAbQzjh7"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9wDzAvE8zjYt"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import optax\n",
        "from flax import linen as nn\n"
      ],
      "metadata": {
        "id": "-Qse0a24zjNm"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## JAX"
      ],
      "metadata": {
        "id": "jG45Ksq0zj53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jax.local_devices() # if there is a device that jax does not see, it needs to be hidden for tf, or whatever is trying to use it\n",
        "    # and you get wery deieving warning here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAesfOCPzlF9",
        "outputId": "7cf61664-1686-49e5-cc81-b05334208e0d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CpuDevice(id=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No datasets and dataloaders in jax - can be fed whatever - numpy arrays, tf.dataset ... Even preprocessing (like in tf.image) is done with tf."
      ],
      "metadata": {
        "id": "2Vilts2S_4HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.sin(x_np) # runs on GPU if found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNPHGsOX_0Ht",
        "outputId": "96494cb8-b225-4fb4-9397-dfba4671d684"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([ 0.9589243 ,  0.95948976,  0.9600514 , ..., -0.9600514 ,\n",
              "       -0.95948976, -0.9589243 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(jnp.sin(x_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdTbfi8cCslI",
        "outputId": "1b030948-44cd-485f-a127-7d476849030f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.ArrayImpl"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike tf and torch, jax is not object oriented, it's functional. All funtions need to be clean (equivalent to the math definition of function) and stateless, so reading global variables, mutation of any kind or random prints are __NOT__ allowed. All functions are cached -> fast computation. That means printing and working with dates outside jax."
      ],
      "metadata": {
        "id": "Niz7zQOwHPNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.arange(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZile7w0HJqs",
        "outputId": "c72def0f-89b0-4c03-c983-586a471646df"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE6FYAPQJiAn",
        "outputId": "32ca79e7-fd5c-4772-f160-abedbcabeadf"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.add(jnp.arange(5), jnp.arange(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ytZi_AdJnlq",
        "outputId": "856f1531-4a0a-4ada-f369-7ec336e1171d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([0, 2, 4, 6, 8], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(20)\n",
        "key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFvLwCEpJz17",
        "outputId": "eae99023-b3e2-4e6c-be4b-532481a3139f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([ 0, 20], dtype=uint32)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jax.random.normal(key, (10, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meYsww_CKDEf",
        "outputId": "a98e0277-bc6a-4370-de45-119f7879f4d1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[-0.26925883,  0.0907927 , -2.3821833 ],\n",
              "       [-1.6529148 ,  0.20920427,  0.41246188],\n",
              "       [-1.1170084 , -0.71164536,  0.2954292 ],\n",
              "       [ 1.4842669 , -1.3843193 ,  0.15493812],\n",
              "       [ 0.03078481,  0.6433308 , -1.4681792 ],\n",
              "       [-0.38111666, -0.5045544 , -1.051294  ],\n",
              "       [ 0.28868425,  0.7171075 ,  0.41290048],\n",
              "       [-0.30961263,  0.09961594,  0.47116306],\n",
              "       [ 1.8791361 , -0.06671944,  0.3367607 ],\n",
              "       [-1.8486868 , -2.33401   , -0.9713245 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data = jax.random.uniform(key, (2000, 6), minval = 0, maxval = 1)"
      ],
      "metadata": {
        "id": "6KihwFL2KEy2"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = jax.random.uniform(key, (6, 1))"
      ],
      "metadata": {
        "id": "yocepr9uLB3y"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data @ weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeLQJUKgLeb3",
        "outputId": "b280ed1c-6205-4a5b-de01-5e2038f81c6e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0.72091424],\n",
              "       [1.7134857 ],\n",
              "       [1.6824692 ],\n",
              "       ...,\n",
              "       [1.5126554 ],\n",
              "       [1.2424307 ],\n",
              "       [1.1728551 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.dot(mock_data, weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7dTLgFnL55Q",
        "outputId": "4694996b-ef04-417c-a2f2-6cd451836796"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[0.72091424],\n",
              "       [1.7134857 ],\n",
              "       [1.6824692 ],\n",
              "       ...,\n",
              "       [1.5126554 ],\n",
              "       [1.2424307 ],\n",
              "       [1.1728551 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Dense(features = 5)\n",
        "layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzIVdWckMNC3",
        "outputId": "397e5e1b-41e7-47b7-c99c-12c692fdc2bd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dense(\n",
              "    # attributes\n",
              "    features = 5\n",
              "    use_bias = True\n",
              "    dtype = None\n",
              "    param_dtype = float32\n",
              "    precision = None\n",
              "    kernel_init = init\n",
              "    bias_init = zeros\n",
              "    dot_general = None\n",
              "    dot_general_cls = None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data = jax.random.normal(key, (10,))"
      ],
      "metadata": {
        "id": "PcvyA7B0NRsA"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer.init(key, mock_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex19w86KN1KY",
        "outputId": "3d3842ce-6574-49a0-a555-66876601f87e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'kernel': Array([[ 0.29296583,  0.0138092 ,  0.00610141, -0.21248457,  0.08460615],\n",
              "         [ 0.29294896,  0.05076104, -0.46301162, -0.5054324 ,  0.23475912],\n",
              "         [-0.15767041,  0.59172344,  0.2567166 ,  0.25704837,  0.38296783],\n",
              "         [-0.17116024, -0.04202386,  0.18405606, -0.0587455 ,  0.04753259],\n",
              "         [-0.02259142, -0.42381543,  0.0794845 ,  0.18145481,  0.66775817],\n",
              "         [ 0.24956997, -0.15160091, -0.37730616, -0.19635604, -0.6289055 ],\n",
              "         [ 0.15924254,  0.41034785,  0.38694903,  0.08089194,  0.07568637],\n",
              "         [ 0.40413558,  0.00290858, -0.04726915, -0.70813113,  0.14452116],\n",
              "         [-0.07867039, -0.17754628, -0.05989967,  0.14621358, -0.15262361],\n",
              "         [ 0.2524277 ,  0.4384316 , -0.69179004,  0.4629794 , -0.09735728]],      dtype=float32),\n",
              "  'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.key(10000)\n",
        "key_data, key_weights = jax.random.split(key)"
      ],
      "metadata": {
        "id": "R6AUHHhhN8GS"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the keys for every usecase, because sequence of operations matters, meaning that after data init, the weights init will depend on how many times was data initiated with the same key."
      ],
      "metadata": {
        "id": "z5B-7tzsO8cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mock_data = jax.random.normal(key_data, (10,))"
      ],
      "metadata": {
        "id": "3JxAJuoiOlPI"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Dense(features = 5)"
      ],
      "metadata": {
        "id": "G4dnHBIbPjDw"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = layer.init(key_weights, mock_data) # x usually, but we have other x above"
      ],
      "metadata": {
        "id": "ky-s3TQJPo9a"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(params[\"params\"][\"kernel\"].ravel())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "FhXJnE2zPtZK",
        "outputId": "04c9c40b-0404-472e-8c7b-0500908bc794"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_util.tree_map(lambda x: x.shape, params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3pwC44CQIHZ",
        "outputId": "41a804e8-4d67-482d-974e-bfaadbbfdb83"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'bias': (5,), 'kernel': (10, 5)}}"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = layer.apply(params, mock_data) # this i y_predicted"
      ],
      "metadata": {
        "id": "9JlQiK87Sizp"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer # layer is just definition of operation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEOZf-3MS5EZ",
        "outputId": "37d956d5-dec7-4baf-9f63-70f9423315d0"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dense(\n",
              "    # attributes\n",
              "    features = 5\n",
              "    use_bias = True\n",
              "    dtype = None\n",
              "    param_dtype = float32\n",
              "    precision = None\n",
              "    kernel_init = init\n",
              "    bias_init = zeros\n",
              "    dot_general = None\n",
              "    dot_general_cls = None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result[2] = 300 # nope, no mutation allowed\n",
        "# result.at[2] = 300 # works but DO NOT DO THAT - no mutation allowed !!!\n",
        "\n",
        "# params = gd(params)"
      ],
      "metadata": {
        "id": "gUy7exWqTGvi"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = nn.Conv(features = 20, kernel_size = 2)"
      ],
      "metadata": {
        "id": "t7LjlTE_TbgK"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conv.init(key_weights, ---)"
      ],
      "metadata": {
        "id": "YqXq2vDrXKP9"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_JAX(nn.Module): # JAX nn not torch.nn\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(32, 3)(x)\n",
        "    x = nn.Dense(20)(x) # 20 params\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "gc4VAOxdX_lb"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/google/flax/blob/main/examples/mnist/train.py"
      ],
      "metadata": {
        "id": "YWFMvHtHcrHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"A simple CNN model.\"\"\"\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "    x = x.reshape((x.shape[0], -1))  # flatten\n",
        "    x = nn.Dense(features=256)(x)\n",
        "    x = nn.relu(x)\n",
        "    x = nn.Dense(features=10)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def apply_model(state, images, labels):\n",
        "  \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
        "\n",
        "  def loss_fn(params):\n",
        "    logits = state.apply_fn({'params': params}, images)\n",
        "    one_hot = jax.nn.one_hot(labels, 10)\n",
        "    loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
        "    return loss, logits\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, logits), grads = grad_fn(state.params)\n",
        "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
        "  return grads, loss, accuracy\n"
      ],
      "metadata": {
        "id": "UfGdijaNYaKs"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step RETURNS the gradients, so that they're not changed inplace\n",
        "# this is a hollow function waiting to be called, so they are not actually calculated by inferrence"
      ],
      "metadata": {
        "id": "tf6wLmHMcnat"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feed data with whatever you like, but leave shuffle to jax\n"
      ],
      "metadata": {
        "id": "TKDPRW4BfddW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/google-research/vision_transformer\n",
        "\n",
        "goes with jax\n",
        "\n",
        "DeepMind - vision and reinforcement learning"
      ],
      "metadata": {
        "id": "tAeDbC3BgKSg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-oaIEfTdgXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}